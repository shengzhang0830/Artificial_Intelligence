{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# String Operations and NumPy Arrays #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab session we'll go over some python methods and general approaches for dealing with strings.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## String Operations ##\n",
    "We'll start with string operations. Below we are given an example sentence. We'll use this sentence to showcase some of the string operations that we could do with string objects in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = \"In the first quarter of fiscal 2018, Walmart reported an astounding figure: 63 percent.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll convert the sentence as a list of words. Python let's us do that with the split() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = d.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the sentence stored as a list we could access each word based on its location within the sentence. The word location is the list index starting from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we could lowercase a word and remove a punctation mark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = words[7]\n",
    "word=word.lower()\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word=words[-1]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word=word.replace(\".\",\"\")\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word=words[-2]\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = words[7]\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the .isdecimal(), .isalpha(), .isdigit() we could check whether the string only contains decimal characters, if the characters in the string are all alphabetic, or if they are all digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word=words[6]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word.isdigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word itself is an array of characters and therefore we could perform array operations on it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = words[7]\n",
    "print(word[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(word[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word could be converted into a list of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = word[:3]\n",
    "characters = list(w)\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do list comprehension over the characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlist = [ch for ch in w]\n",
    "print(wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Assignment 1]**\n",
    "Find an online sentence or a paragraph and explore the different string operations on your own. \n",
    "A list of the various striwng methods could be found here:  \n",
    "https://docs.scipy.org/doc/numpy/reference/routines.char.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Solution 1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Representations ##\n",
    "Next we'll look into how we could store and represent words for various NLP approaches using NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words as array indices ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Federal Reserve considers transparency about the goals, conduct, and stance of monetary policy to be fundamental to the effectiveness of monetary policy. The Federal Reserve Act sets forth the goals of monetary policy.\n"
     ]
    }
   ],
   "source": [
    "para=\"The Federal Reserve considers transparency about the goals, conduct, and stance of monetary policy to be fundamental to the effectiveness of monetary policy. The Federal Reserve Act sets forth the goals of monetary policy.\"\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases words are represented as array indices by assigning them with integer values. This representation type requires less memory and is more time efficient. This is done by creating a dictionary of words where each word is a key whose dictionary value is the assigned key (integer). In this representation type sentences are integer arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The' 'Federal' 'Reserve' 'considers' 'transparency' 'about' 'the'\n",
      " 'goals,' 'conduct,' 'and' 'stance' 'of' 'monetary' 'policy' 'to' 'be'\n",
      " 'fundamental' 'to' 'the' 'effectiveness' 'of' 'monetary' 'policy.' 'The'\n",
      " 'Federal' 'Reserve' 'Act' 'sets' 'forth' 'the' 'goals' 'of' 'monetary'\n",
      " 'policy.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "words = np.array(para.split())\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'Federal': 1, 'Reserve': 2, 'considers': 3, 'transparency': 4, 'about': 5, 'the': 6, 'goals,': 7, 'conduct,': 8, 'and': 9, 'stance': 10, 'of': 11, 'monetary': 12, 'policy': 13, 'to': 14, 'be': 15, 'fundamental': 16, 'effectiveness': 17, 'policy.': 18, 'Act': 19, 'sets': 20, 'forth': 21, 'goals': 22}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 14, 6, 17, 11, 12, 18, 0, 1, 2, 19, 20, 21, 6, 22, 11, 12, 18]\n"
     ]
    }
   ],
   "source": [
    "dictionary = dict()\n",
    "words_index = list()\n",
    "index=0\n",
    "for word in words:\n",
    "    if (word in dictionary.keys()):\n",
    "        words_index.append(dictionary[word]) \n",
    "    else:\n",
    "        dictionary[word]=index\n",
    "        words_index.append(index)\n",
    "        index+=1\n",
    "     \n",
    "print(dictionary)\n",
    "print(words_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\t0\n",
      "Federal\t1\n",
      "Reserve\t2\n",
      "considers\t3\n",
      "transparency\t4\n",
      "about\t5\n",
      "the\t6\n",
      "goals,\t7\n",
      "conduct,\t8\n",
      "and\t9\n",
      "stance\t10\n",
      "of\t11\n",
      "monetary\t12\n",
      "policy\t13\n",
      "to\t14\n",
      "be\t15\n",
      "fundamental\t16\n",
      "to\t14\n",
      "the\t6\n",
      "effectiveness\t17\n",
      "of\t11\n",
      "monetary\t12\n",
      "policy.\t18\n",
      "The\t0\n",
      "Federal\t1\n",
      "Reserve\t2\n",
      "Act\t19\n",
      "sets\t20\n",
      "forth\t21\n",
      "the\t6\n",
      "goals\t22\n",
      "of\t11\n",
      "monetary\t12\n",
      "policy.\t18\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(words)):\n",
    "    print (str(words[i])+\"\\t\"+str(words_index[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.size\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words as binary vectors ###\n",
    "In NLP applications such as classification, regression and clustering and for some neural network based approaches it is more convenient to represent words as binary vectors whose number of dimensions is the vocabulary length $|V|$. In representation type a word has all vector dimensions equal to zero except for its corresponding dimension which is equal to its assigned index. This is also known as a one-hot representation or encoding. For example, let's assume that we have a vocabulary of 3 words, e.g. $V$= {color, money , green}. In the one-hot representation we assign each word with its own dimension which generates the following representation:\n",
    "\n",
    "color = [1,0,0]\n",
    "\n",
    "money = [0,1,0]\n",
    "\n",
    "green =[0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 14, 6, 17, 11, 12, 18, 0, 1, 2, 19, 20, 21, 6, 22, 11, 12, 18]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dsize = len(dictionary)\n",
    "para_oh = list()\n",
    "print(words_index)\n",
    "for index in words_index:\n",
    "    temp = np.zeros(dsize)\n",
    "    temp[index]=1\n",
    "    para_oh.append(temp)\n",
    "para_oh = np.array(para_oh)\n",
    "print(para_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words as tuples of frequency counts ###\n",
    "When the word ordering is not important, text (i.e. documents, paragraphs, sentences, etc.) is represented through the bag of words approach. This type of an approach only considers the frequency of occurrence of the words in the text. It is typically performed by going over the words $w$ and counting the number of times each word occurs. Once statistics are collected the text represented as a set of tuples which consists of the word index and the frequency count $fc(w)$:\n",
    "\n",
    "{$w$,$fc(w)$)\n",
    "\n",
    "For example, the following sentence:  \n",
    "\"We have 47 prefectures and each prefecture will have a store in Tokyo.\"  \n",
    "\n",
    "would be represented as:  \n",
    "[(0,1), (1,2), (2,1), (3,2), (4,1), (5,1), (6,1), (7,1), (8,1), (9,1), (10,1)]  \n",
    "\n",
    "Let's now represent the paragraph using the bag of words approach: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 1: 2, 2: 2, 3: 1, 4: 1, 5: 1, 6: 3, 7: 1, 8: 1, 9: 1, 10: 1, 11: 3, 12: 3, 13: 1, 14: 2, 15: 1, 16: 1, 17: 1, 18: 2, 19: 1, 20: 1, 21: 1, 22: 1}\n",
      "['(0:2)', '(1:2)', '(2:2)', '(3:1)', '(4:1)', '(5:1)', '(6:3)', '(7:1)', '(8:1)', '(9:1)', '(10:1)', '(11:3)', '(12:3)', '(13:1)', '(14:2)', '(15:1)', '(16:1)', '(17:1)', '(18:2)', '(19:1)', '(20:1)', '(21:1)', '(22:1)']\n"
     ]
    }
   ],
   "source": [
    "bow = dict()\n",
    "index=0\n",
    "for index in words_index:\n",
    "    if (index in bow.keys()):\n",
    "        bow[index]+=1\n",
    "    else:\n",
    "        bow[index]=1\n",
    "\n",
    "print (bow)\n",
    "para_bow = list()\n",
    "for index in bow.keys():\n",
    "    para_bow.append(\"(\"+str(index)+\":\"+str(bow[index])+\")\")\n",
    "print (para_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**[Assignment 2]**\n",
    "At the beginning of this lab sessions we learned how we could lowercase a word and replace a character. Use these two operations to generate a new dictionary where all words are lowercased and periods (\".\"), commas (\",\") and colons (\":\") removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Solution 2]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
