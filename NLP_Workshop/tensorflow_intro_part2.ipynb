{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with TensorFlow\n",
    "\n",
    "[**Important.** If you are not familiar with logistic regression, then you should try this tutorial _after_ tomorrow's session, where we will learn about logistic regression. If you already know what it is about, then you can go ahead with this notebook.]\n",
    "\n",
    "Given what you have learned, can you develop logistic regression now? In logistic regression, the dependent variable `y` is binary, and its expectation (the probability that $y=1$) is\n",
    "$$\n",
    "\\textrm{Prob}(y=1|x) = \\sigma(w^\\top x + b),\n",
    "$$\n",
    "where $\\sigma(x) = \\frac{1}{1+\\exp(-x)}$ is the sigmoid function. The sigmoid function, which returns a number between 0 and 1, is available as `tf.sigmoid` in TensorFlow, or `scipy.special.expit` in Scipy.\n",
    "\n",
    "**Import the packages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**Generate the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# True coefficients\n",
    "true_weights = np.array([-3.0])\n",
    "true_intercept = 1.0\n",
    "\n",
    "# Generate N 1-dimensional locations X at random\n",
    "N = 40\n",
    "num_dim = 1\n",
    "x_data = np.random.rand(N, num_dim).astype(np.float32) # Conversion to type float required for TF\n",
    "\n",
    "# Generate the dependent variable y\n",
    "y_data_logistic = (np.random.rand(N) < expit(np.matmul(x_data, true_weights) + true_intercept)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the data.** As a sanity check, we plot the data, together with the underlying probability $\\textrm{Pr}(y=1|x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.plot(x_data[:,0], y_data_logistic, '.')\n",
    "# Plot the probability P(y=1) on top\n",
    "x_loc = np.expand_dims(np.linspace(0.0, 1.0, num=200), axis=1)\n",
    "y_loc = expit(np.matmul(x_loc, true_weights) + true_intercept)\n",
    "plt.plot(x_loc, y_loc, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Graph\n",
    "\n",
    "This steps are analogous to the linear regression case.\n",
    "\n",
    "**Declare the variables.** The variables remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.random_uniform([num_dim, 1], -1.0, 1.0))\n",
    "intercept = tf.Variable(tf.constant(0.0, shape=[1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the loss.** The loss function needs to be changed with respect to the linear regression case. In logistic regression, it is given by\n",
    "$$\\mathcal{L} = \\frac{1}{N}\\sum_{n=1}^N y_n \\log\\sigma(w^\\top x + b) + (1-y_n) \\log\\left(1-\\sigma(w^\\top x + b)\\right).$$\n",
    "\n",
    "Fortunately, TensorFlow has a function that computes that, called `tf.nn.sigmoid_cross_entropy_with_logits`. It receives the *labels* $y$ and the *logits* $w^\\top x + b$.The loss\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{N}\\sum_{n=1}^{N} \\left( \\hat{y}_n - y_n \\right)^2,\\qquad\n",
    "\\textrm{with} \\quad \\hat{y}_n = b+w^\\top x_n.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = intercept + tf.matmul(x_data, weight)\n",
    "loss_logistic = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.squeeze(y_predicted), labels=y_data_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer.** This is the same as in the linear regression case. Although we are optimizing a more complex function, we don't need to change this piece of code! That is the main advantage of TensorFlow (and similar packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an optimizer. We will use a simple gradient descent optimizer\n",
    "learning_rate = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss_logistic) # We need to specify which variable we want to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "We can only evaluate variables and perform computations within a TensorFlow session. We will create a session that:\n",
    "1. Initializes the variables (weight and intercept).\n",
    "2. Runs gradient descent to minimize the loss. We use a `for` loop for that.\n",
    "3. Prints the progress.\n",
    "\n",
    "**[Task]** In the cell below, create a session to run gradient descent, with $5000$ iterations. You do *not* need to plot the results after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** Do we recover the weight and intercept as accurately as in linear regression? Why/Why not?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
